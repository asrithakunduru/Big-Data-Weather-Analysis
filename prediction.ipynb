{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd70d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+------------------+\n",
      "|      city|avg_temperature|        prediction|\n",
      "+----------+---------------+------------------+\n",
      "|  Edmonton|         262.48| 268.5008786961388|\n",
      "|   Kelowna|         272.62| 271.7033973084038|\n",
      "| Saskatoon|         263.14| 273.2763239817554|\n",
      "|St. John's|         278.63|274.02695843480956|\n",
      "|Whitehorse|         256.99| 274.9225148431824|\n",
      "+----------+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"WeatherPrediction\").getOrCreate()\n",
    "\n",
    "# Define the schema for the CSV data\n",
    "schema = StructType([\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"temperature\", StringType(), True),\n",
    "    StructField(\"humidity\", StringType(), True),\n",
    "    StructField(\"weather_description\", StringType(), True),\n",
    "    StructField(\"wind_speed\", StringType(), True),\n",
    "    StructField(\"cloudiness\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Read CSV data into a Spark DataFrame with the defined schema\n",
    "csv_file_path = 'file:///C:/WeatherMonitoringSystem/weather_forecast.csv'\n",
    "weather_df = spark.read.csv(csv_file_path, header=True, schema=schema)\n",
    "\n",
    "# Convert temperature, humidity, wind_speed, and cloudiness columns to numeric types\n",
    "numeric_columns = [\"temperature\", \"humidity\", \"wind_speed\", \"cloudiness\"]\n",
    "for column in numeric_columns:\n",
    "    weather_df = weather_df.withColumn(column, weather_df[column].cast(\"double\"))\n",
    "\n",
    "# Calculate average temperature, humidity, wind_speed, and cloudiness for each city\n",
    "average_stats = weather_df.groupBy(\"city\").agg(\n",
    "    avg(\"temperature\").alias(\"avg_temperature\"),\n",
    "    avg(\"humidity\").alias(\"avg_humidity\"),\n",
    "    avg(\"wind_speed\").alias(\"avg_wind_speed\"),\n",
    "    avg(\"cloudiness\").alias(\"avg_cloudiness\")\n",
    ")\n",
    "\n",
    "# Create a feature vector by assembling the features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"avg_humidity\", \"avg_wind_speed\", \"avg_cloudiness\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Create a Linear Regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"avg_temperature\")\n",
    "\n",
    "# Create a pipeline with the assembler and the linear regression model\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = average_stats.randomSplit([0.8, 0.2], seed=123)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show the predicted values alongside the actual values\n",
    "predictions.select(\"city\", \"avg_temperature\", \"prediction\").show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27f223d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Toronto on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Vancouver on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Calgary on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Montreal on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Edmonton on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Ottawa on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Quebec City on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Winnipeg on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Halifax on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Victoria on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Regina on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Saskatoon on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for St. John's on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Hamilton on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Kelowna on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for London on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Thunder Bay on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Charlottetown on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Fredericton on 2023-12-03 stored in CSV file and published to Kafka.\n",
      "Data for Whitehorse on 2023-12-03 stored in CSV file and published to Kafka.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from kafka import KafkaProducer\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define your list of cities in Canada with unpredictable weather\n",
    "cities = ['Toronto', 'Vancouver', 'Calgary', 'Montreal', 'Edmonton', \n",
    "          'Ottawa', 'Quebec City', 'Winnipeg', 'Halifax', 'Victoria', \n",
    "          'Regina', 'Saskatoon', 'St. John\\'s', 'Hamilton', 'Kelowna', \n",
    "          'London', 'Thunder Bay', 'Charlottetown', 'Fredericton', 'Whitehorse']\n",
    "\n",
    "# Kafka producer setup\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "\n",
    "# OpenWeather API key\n",
    "openweather_api_key = '56718e7590a2f67ca64cfb140da39658'\n",
    "\n",
    "# Columns to extract for CSV file\n",
    "csv_columns = ['city', 'date', 'temperature', 'humidity', 'weather_description', 'wind_speed', 'cloudiness']\n",
    "\n",
    "# File to save the data\n",
    "csv_file_path = r'C:\\WeatherMonitoringSystem\\predict_forecast.csv'\n",
    "\n",
    "# Open CSV file for writing\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "\n",
    "# Fetch data for each city and write to CSV\n",
    "for city in cities:\n",
    "    # Calculate the date for the next day\n",
    "    next_day = datetime.now() + timedelta(days=1)\n",
    "    next_day_str = next_day.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    url = f'http://api.openweathermap.org/data/2.5/forecast?q={city},CA&appid={openweather_api_key}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        weather_data = response.json()\n",
    "\n",
    "        # Extract necessary fields for CSV for the next day\n",
    "        for entry in weather_data.get('list', []):\n",
    "            timestamp = entry.get('dt', 0)\n",
    "            date = datetime.utcfromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            # Check if the entry corresponds to the next day\n",
    "            if date.startswith(next_day_str):\n",
    "                extracted_data = {\n",
    "                    'city': city,\n",
    "                    'date': date,\n",
    "                    'temperature': entry.get('main', {}).get('temp', ''),\n",
    "                    'humidity': entry.get('main', {}).get('humidity', ''),\n",
    "                    'weather_description': entry.get('weather', [{}])[0].get('description', ''),\n",
    "                    'wind_speed': entry.get('wind', {}).get('speed', ''),\n",
    "                    'cloudiness': entry.get('clouds', {}).get('all', '')\n",
    "                }\n",
    "\n",
    "                # Write data to CSV file\n",
    "                with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "                    writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "                    writer.writerow(extracted_data)\n",
    "\n",
    "                # Publish data to Kafka\n",
    "                producer.send('weather_topic', json.dumps(extracted_data).encode('utf-8'))\n",
    "\n",
    "                print(f\"Data for {city} on {next_day_str} stored in CSV file and published to Kafka.\")\n",
    "                break  # Stop after finding the entry for the next day\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {city}. Status code: {response.status_code}\")\n",
    "\n",
    "# Close the Kafka producer\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944de3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
